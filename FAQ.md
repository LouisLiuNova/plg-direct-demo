# Q&A

## 1. 数据偏移问题

**Q：为什么在环境变量中设定了 `APP_TPS=20` 和 `APP_LOSS_RATE=0.2` (20%)，但 Grafana 监控面板上显示的实际 Loss Rate 却只有 0.03 (3%) 左右？**

**A:**
这是由于分布式容器环境下，**“生产端实际性能”**与**“消费端模拟基准”**不匹配导致的统计偏差。

1.  **转发服务 (In) 的性能损耗**：
    虽然配置了 `TPS=20`，但由于 Python 脚本的执行开销、Docker 容器的文件 IO 写入延迟以及代码中模拟的 `interference_delay`，导致转发服务的**实际产出速率**往往达不到理论值（实测通常在 **16.3 TPS** 左右）。
2.  **处理服务 (Out) 的基准计算**：
    处理服务的逻辑主要负责分发任务到线程池，IO 阻塞极少，因此它能精准地以配置的 `TPS=20` 为基准进行计算。其输出量为：`20 * (1 - 0.2) = 16.0 TPS`。
3.  **偏差结果**：
    监控系统计算的丢包率为：`(16.3 - 16.0) / 16.3 ≈ 1.8%`。原本预期的 20% 差距被转发服务的性能损耗意外填平了。

建议观察 Grafana 中转发服务的**实际 TPS**（例如 16.5），然后将 `docker-compose.yaml` 中处理服务 (`processor-app`) 的 `APP_TPS` 环境变量**下调至该数值**，手动对齐基准，即可获得精准的丢包率演示效果。

---

## 2. 数据波动问题

**Q: 为什么在流量对比图中，转发服务 (In) 的曲线非常平滑，而处理服务 (Out) 的曲线却呈现出剧烈的锯齿状波动？**

**A:**
这种差异反映了**“确定性系统”**与**“随机性系统”**在统计学表现上的本质区别，也是真实分布式系统的典型特征。

> [!NOTE]
> 项目的模拟机制如下：
> 1. 转发服务按照设定的TPS产生日志，产生符合`TPS`设定数量的日志
> 2. 处理服务在处理完成后会进行基于`LOSS_RATE`的随机检查,如果没有通过**会在这里丢包而不是在转发服务**.如果通过检查,则打印成功日志

1.  **In 曲线平滑 (确定性)**：
    转发服务的代码逻辑是单线程、固定间隔（Fixed Interval）的循环。它像一个节拍器，以极其稳定的速率产生日志，因此在统计窗口内的方差极小，曲线表现平滑。
2.  **Out 曲线波动 (随机性)**：
    处理服务的输出受两个随机变量叠加影响：
    *   **概率丢包**：基于伯努利试验（Bernoulli Trial）的随机丢包，导致进入处理队列的任务数量本身就在波动。
    *   **随机时延 (Latency Jitter)**：这是主因。每个任务的处理耗时在 `50ms ~ 500ms` 之间随机分布。这导致任务虽然均匀进入，但**完成时间**会发生重叠或错位（例如长耗时任务和短耗时任务在同一秒结束），从而导致单位时间内的日志输出量忽高忽低。

这种波动是正常的，它真实地模拟了下游服务因处理耗时差异（Processing Time Variance）而产生的**流量抖动 (Traffic Jitter)** 现象。